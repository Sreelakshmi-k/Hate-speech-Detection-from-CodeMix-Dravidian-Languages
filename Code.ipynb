{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is for HOS using multilingual Embeddings for three Dravidian CodeMix languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"malayalam_offensive_train.csv\")\n",
    "test = pd.read_csv(\"mal_full_offensive_test.csv\",header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sperate the train and test senetnecs and labels to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent_m=[]\n",
    "train_label_m=[]\n",
    "test_sent_m = []\n",
    "test_label_m = []\n",
    "\n",
    "for i in train['0']:\n",
    "    train_sent_m.append(i.split('\\t')[0])\n",
    "    train_label_m.append(i.split('\\t')[1])\n",
    "\n",
    "for i in test[0]:\n",
    "    test_sent_m.append(i.split('\\t')[0])\n",
    "    test_label_m.append(i.split('\\t')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_labels_encoded = le.fit_transform(train_label_m)\n",
    "dev_labels_encoded = le.fit_transform(test_label_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_model = SentenceTransformer('bert-base-multilingual-cased')\n",
    "# here other multilingual embeddings can be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence_embeddings = trans_model.encode(train_sent_m)\n",
    "dev_sentence_embeddings = trans_model.encode(test_sent_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = sklearn.utils.class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_label_m),\n",
    "                                                 train_label_m)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "class_weight = {0:0.22607331, 1:23.54117647 ,2:13.69505703 ,3:17.07014218 ,4:2.484}\n",
    "model = LogisticRegression(class_weight=class_weight)\n",
    "model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv \n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('Logistic_regression.csv')\n",
    "print(\"prediction saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot=True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_LR.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAive Baise\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "model = GaussianNB()\n",
    "model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv \n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('Naive_baise.csv')\n",
    "print(\"prediction saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot=True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_NB.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "class_weight = {0:0.22607331, 1:23.54117647 ,2:13.69505703 ,3:17.07014218 ,4:2.484}\n",
    "model = RandomForestClassifier(n_estimators=100, class_weight=class_weight)\n",
    "model = model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv \n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('RF.csv')\n",
    "print(\"prediction saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot=True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_RF.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM rbf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "class_weight = {0:0.22607331, 1:23.54117647 ,2:13.69505703 ,3:17.07014218 ,4:2.484}\n",
    "model = svm.SVC(kernel='rbf',C = 1000, class_weight =class_weight)\n",
    "model = model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv \n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('SVM_RBF.csv')\n",
    "print(\"prediction saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot=True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_SVM_rbf.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM poly\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='poly',C = 1000)\n",
    "model = model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv \n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('SVM_poly_labse.csv')\n",
    "print(\"prediction saved\")\n",
    "\n",
    "#Save model\n",
    "import pickle\n",
    "# Save the trained model as a pickle string.\n",
    "pkl_filename = \"poly_labse.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot =True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_SVM_poly_labse.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Linear\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='linear',C = 10)\n",
    "model = model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv \n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('SVM_linear_labse.csv')\n",
    "print(\"prediction saved\")\n",
    "\n",
    "#Save model\n",
    "import pickle\n",
    "# Save the trained model as a pickle string.\n",
    "pkl_filename = \"linear_labse.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot =True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_SVM_linear_labse.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(n_estimators=100)\n",
    "model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv \n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('Adaboost.csv')\n",
    "print(\"prediction saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot=True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_adaboost.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(weights = 'distance')\n",
    "model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv \n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('KNN.csv')\n",
    "print(\"prediction saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot=True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_KNN.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "class_weight = {0:0.22607331, 1:23.54117647 ,2:13.69505703 ,3:17.07014218 ,4:2.484}\n",
    "model = DecisionTreeClassifier(class_weight=class_weight)\n",
    "model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv \n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('DT.csv')\n",
    "print(\"prediction saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
